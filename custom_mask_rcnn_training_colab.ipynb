{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinhthixuanbinh/object-detection/blob/main/custom_mask_rcnn_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"...\")\n",
        "project = rf.workspace(\"hadv2\").project(\"had-v2\")\n",
        "version = project.version(8)\n",
        "dataset = version.download(\"coco\")\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:35:42.025762Z",
          "iopub.execute_input": "2024-11-18T15:35:42.026153Z",
          "iopub.status.idle": "2024-11-18T15:36:19.019681Z",
          "shell.execute_reply.started": "2024-11-18T15:35:42.026109Z",
          "shell.execute_reply": "2024-11-18T15:36:19.018794Z"
        },
        "id": "3Zsxb5R7NJju",
        "outputId": "66e1d1dd-c5dc-4f4e-8685-b7d261273fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting roboflow\n  Downloading roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from roboflow) (2024.8.30)\nRequirement already satisfied: idna==3.7 in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7)\nRequirement already satisfied: cycler in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (10.3.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.4)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.53.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.49-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: filetype, roboflow\nSuccessfully installed filetype-1.2.0 roboflow-1.1.49\nloading Roboflow workspace...\nloading Roboflow project...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Downloading Dataset Version Zip in HAD-v2-8 to coco:: 100%|██████████| 803926/803926 [00:18<00:00, 43910.63it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\nExtracting Dataset Version Zip to HAD-v2-8 in coco:: 100%|██████████| 9168/9168 [00:02<00:00, 3653.10it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/working/dataset.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "from loguru import logger\n",
        "\n",
        "class COCODetectionDataset(Dataset):\n",
        "    def __init__(self, root, annotation_file, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.coco = COCO(annotation_file)\n",
        "\n",
        "        self.class_map = {\n",
        "            'bus': 1,\n",
        "            'car': 2,\n",
        "            'crosswalk': 3,\n",
        "            'person': 4,\n",
        "            'stop sign': 5,\n",
        "            'traffic light': 6,\n",
        "            'truck': 7\n",
        "        }\n",
        "\n",
        "        self.category_mapping = {}\n",
        "        for cat in self.coco.loadCats(self.coco.getCatIds()):\n",
        "            if cat['name'] in self.class_map:\n",
        "                self.category_mapping[cat['id']] = self.class_map[cat['name']]\n",
        "\n",
        "        all_image_ids = self.coco.getImgIds()\n",
        "        valid_image_ids = []\n",
        "        for img_id in all_image_ids:\n",
        "            ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "            if len(ann_ids) > 0:\n",
        "                valid_image_ids.append(img_id)\n",
        "        self.ids = sorted(valid_image_ids)\n",
        "\n",
        "        logger.info(f\"Loaded dataset with {len(self.ids)} valid images and {len(self.class_map)} classes\")\n",
        "        logger.info(f\"Classes: {list(self.class_map.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        coco_annotations = self.coco.loadAnns(ann_ids)\n",
        "        image_info = self.coco.loadImgs(img_id)[0]\n",
        "\n",
        "        try:\n",
        "            image_path = os.path.join(self.root, image_info['file_name'])\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading image {image_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        areas = []\n",
        "        iscrowd = []\n",
        "\n",
        "        for ann in coco_annotations:\n",
        "            if ann['category_id'] not in self.category_mapping:\n",
        "                continue\n",
        "\n",
        "            x_min, y_min, width, height = ann['bbox']\n",
        "            if width <= 0 or height <= 0:\n",
        "                continue\n",
        "\n",
        "            x_max = x_min + width\n",
        "            y_max = y_min + height\n",
        "\n",
        "            boxes.append([x_min, y_min, x_max, y_max])\n",
        "            labels.append(self.category_mapping[ann['category_id']] - 1)\n",
        "            areas.append(width * height)\n",
        "            iscrowd.append(ann.get('iscrowd', 0))\n",
        "\n",
        "        if not boxes:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            areas = torch.zeros((0,), dtype=torch.float32)\n",
        "            iscrowd = torch.zeros((0,), dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "            iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([img_id]),\n",
        "            'area': areas,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, target"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:19.021743Z",
          "iopub.execute_input": "2024-11-18T15:36:19.022097Z",
          "iopub.status.idle": "2024-11-18T15:36:19.030572Z",
          "shell.execute_reply.started": "2024-11-18T15:36:19.022042Z",
          "shell.execute_reply": "2024-11-18T15:36:19.029607Z"
        },
        "id": "O5K4vamFNJjw",
        "outputId": "3691b82e-4106-413f-b8b0-b2ec86a68c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Writing /kaggle/working/dataset.py\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/working/GPU_optimizer.py\n",
        "# GPU_optimizer.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from loguru import logger\n",
        "import time\n",
        "\n",
        "class GPUOptimizer:\n",
        "    \"\"\"Utility class for GPU memory optimization in deep learning training.\"\"\"\n",
        "\n",
        "    def __init__(self, device='cuda'):\n",
        "        self.device = device\n",
        "        self.grad_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_optimal_batch_size(model, sample_input, device, start_batch_size=4):\n",
        "        \"\"\"Dynamically find the largest batch size that fits in memory.\"\"\"\n",
        "        batch_size = start_batch_size\n",
        "        while batch_size > 0:\n",
        "            try:\n",
        "                # Try to process a batch\n",
        "                sample_batch = [sample_input] * batch_size\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    _ = model(sample_batch)\n",
        "                torch.cuda.empty_cache()\n",
        "                return batch_size\n",
        "            except torch.cuda.OutOfMemoryError:\n",
        "                batch_size = batch_size // 2\n",
        "                torch.cuda.empty_cache()\n",
        "        raise RuntimeError(\"Could not find a valid batch size\")\n",
        "\n",
        "    @staticmethod\n",
        "    def optimize_dataloader(dataset, batch_size, num_workers, collate_fn=None):\n",
        "        \"\"\"Create a memory-optimized DataLoader.\"\"\"\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=num_workers,\n",
        "            collate_fn=collate_fn,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "    def get_cuda_streams(self):\n",
        "        \"\"\"Get CUDA streams for overlapped computation.\"\"\"\n",
        "        return {\n",
        "            'data': torch.cuda.Stream(),\n",
        "            'compute': torch.cuda.Stream()\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_memory_stats():\n",
        "        \"\"\"Get current GPU memory statistics.\"\"\"\n",
        "        return {\n",
        "            'allocated': f\"{torch.cuda.memory_allocated() / 1024**2:.1f}MB\",\n",
        "            'cached': f\"{torch.cuda.memory_reserved() / 1024**2:.1f}MB\",\n",
        "            'max_allocated': f\"{torch.cuda.max_memory_allocated() / 1024**2:.1f}MB\"\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def handle_oom_error(iteration):\n",
        "        \"\"\"Handle out-of-memory errors.\"\"\"\n",
        "        torch.cuda.empty_cache()\n",
        "        memory_stats = GPUOptimizer.get_memory_stats()\n",
        "        logger.error(\n",
        "            f\"OOM error at iteration {iteration}. \"\n",
        "            f\"Current memory state: {memory_stats}\"\n",
        "        )\n",
        "\n",
        "    def enable_memory_efficient_training(self, model):\n",
        "        \"\"\"Enable memory-efficient training features for the model.\"\"\"\n",
        "        if hasattr(model, 'gradient_checkpointing_enable'):\n",
        "            model.gradient_checkpointing_enable()\n",
        "        return model\n",
        "\n",
        "    def to_device(self, data, non_blocking=True):\n",
        "        \"\"\"Efficiently move data to GPU.\"\"\"\n",
        "        if isinstance(data, (list, tuple)):\n",
        "            return [self.to_device(item) for item in data]\n",
        "        elif isinstance(data, dict):\n",
        "            return {k: self.to_device(v) for k, v in data.items()}\n",
        "        elif hasattr(data, 'to'):\n",
        "            return data.to(self.device, non_blocking=non_blocking)\n",
        "        return data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:19.031855Z",
          "iopub.execute_input": "2024-11-18T15:36:19.032218Z",
          "iopub.status.idle": "2024-11-18T15:36:19.045035Z",
          "shell.execute_reply.started": "2024-11-18T15:36:19.032177Z",
          "shell.execute_reply": "2024-11-18T15:36:19.044125Z"
        },
        "id": "QU5iIYcqNJjx",
        "outputId": "8cc3e31e-287a-4408-f7db-b2b4b674da13"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Writing /kaggle/working/GPU_optimizer.py\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/working/trainer.py\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from loguru import logger\n",
        "import torchvision\n",
        "from torchvision.models.detection import (\n",
        "    maskrcnn_resnet50_fpn,\n",
        "    fasterrcnn_resnet50_fpn\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "from config import TrainingConfig\n",
        "from GPU_optimizer import GPUOptimizer\n",
        "\n",
        "class ObjectDetectionTrainer:\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "        self.device = torch.device(config.DEVICE)\n",
        "        self.gpu_optimizer = GPUOptimizer(self.device)\n",
        "        self._setup_logging()\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        logger.add(self.config.LOG_FILE, rotation=\"100 MB\")\n",
        "        logger.info(f\"Using device: {self.device}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        batch = list(filter(lambda x: x is not None, batch))\n",
        "        if not batch:\n",
        "            return [], []\n",
        "        return tuple(zip(*batch))\n",
        "\n",
        "    def _get_model(self, model_name: str):\n",
        "        logger.info(f\"Initializing {model_name} model...\")\n",
        "        try:\n",
        "            model = fasterrcnn_resnet50_fpn(num_classes=self.config.NUM_CLASSES)\n",
        "            model = model.to(self.device)\n",
        "            model.train()\n",
        "            logger.info(f\"Successfully initialized {model_name} model\")\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error initializing model {model_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _get_optimizer(self, model):\n",
        "        return torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=self.config.LEARNING_RATE,\n",
        "            weight_decay=self.config.WEIGHT_DECAY\n",
        "        )\n",
        "\n",
        "    def _get_scheduler(self, optimizer):\n",
        "        return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min',\n",
        "            patience=3,\n",
        "            factor=0.1\n",
        "        )\n",
        "\n",
        "    def train_one_epoch(self, model, optimizer, scheduler, model_name, epoch):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (images, targets) in enumerate(self.train_loader):\n",
        "            try:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                if not images or not targets:\n",
        "                    continue\n",
        "\n",
        "                images = [image.to(self.device) for image in images]\n",
        "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    loss_dict = model(images, targets)\n",
        "                    losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                    if not torch.isfinite(losses):\n",
        "                        logger.warning(f\"Loss is {losses}, skipping batch\")\n",
        "                        continue\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                losses.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
        "\n",
        "                optimizer.step()\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step()\n",
        "\n",
        "                running_loss += losses.detach().cpu().item()\n",
        "\n",
        "                if i % 10 == 0:\n",
        "                    avg_loss = running_loss / (i + 1)\n",
        "                    current_lr = optimizer.param_groups[0]['lr']\n",
        "                    memory_stats = self.gpu_optimizer.get_memory_stats()\n",
        "                    logger.info(\n",
        "                        f\"Epoch {epoch}, Iteration {i}, \"\n",
        "                        f\"Loss: {avg_loss:.4f}, \"\n",
        "                        f\"LR: {current_lr:.6f}, \"\n",
        "                        f\"Memory: {memory_stats}\"\n",
        "                    )\n",
        "\n",
        "                del images, targets, losses, loss_dict\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in training: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        avg_loss = running_loss / len(self.train_loader)\n",
        "        fps = len(self.train_loader.dataset) / elapsed_time\n",
        "\n",
        "        return {\n",
        "            'avg_loss': avg_loss,\n",
        "            'fps': fps,\n",
        "            'elapsed_time': elapsed_time\n",
        "        }\n",
        "    def _get_scheduler(self, optimizer):\n",
        "        num_steps = len(self.train_loader) * self.config.NUM_EPOCHS\n",
        "        warmup_steps = len(self.train_loader)\n",
        "\n",
        "        def lr_lambda(step):\n",
        "            if step < warmup_steps:\n",
        "                return float(step) / float(max(1, warmup_steps))\n",
        "            return 0.1 ** (step / num_steps)\n",
        "\n",
        "        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "    def validate(self, model, val_loader):\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, targets in val_loader:\n",
        "                images = [image.to(self.device) for image in images]\n",
        "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                loss_dict = model(images, targets)\n",
        "                total_loss += sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        fps = len(val_loader.dataset) / elapsed_time\n",
        "\n",
        "        return {\n",
        "            'map': avg_loss.item(),  # Using loss as proxy for mAP\n",
        "            'val_fps': fps,\n",
        "            'elapsed_time': elapsed_time\n",
        "        }\n",
        "\n",
        "    def save_checkpoint(self, model, optimizer, scheduler, metrics, model_name, epoch, is_best=False):\n",
        "        checkpoint_dir = os.path.join(self.config.MODEL_DIR, model_name)\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'metrics': metrics,\n",
        "        }\n",
        "\n",
        "        if is_best:\n",
        "            path = os.path.join(checkpoint_dir, 'model_best.pth')\n",
        "            logger.info(f\"Saving best model with metrics: {metrics}\")\n",
        "        else:\n",
        "            path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
        "            logger.info(f\"Saving checkpoint to {path}\")\n",
        "\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    def train(self, model_name: str, train_loader, val_loader):\n",
        "        logger.info(f\"Starting training for model: {model_name}\")\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        model = self._get_model(model_name)\n",
        "        optimizer = self._get_optimizer(model)\n",
        "        scheduler = self._get_scheduler(optimizer)\n",
        "\n",
        "        best_map = float('inf')\n",
        "        metrics_summary = []\n",
        "\n",
        "        for epoch in range(self.config.NUM_EPOCHS):\n",
        "            logger.info(f\"Starting epoch {epoch}\")\n",
        "\n",
        "            train_metrics = self.train_one_epoch(model, optimizer, scheduler, model_name, epoch)\n",
        "            val_metrics = self.validate(model, val_loader)\n",
        "\n",
        "            epoch_metrics = {\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_metrics['avg_loss'],\n",
        "                'train_fps': train_metrics['fps'],\n",
        "                'val_loss': val_metrics['map'],\n",
        "                'val_fps': val_metrics['val_fps'],\n",
        "                'learning_rate': optimizer.param_groups[0]['lr']\n",
        "            }\n",
        "            metrics_summary.append(epoch_metrics)\n",
        "\n",
        "            logger.info(\"\\n\" + \"=\"*50)\n",
        "            logger.info(f\"Epoch {epoch} Summary:\")\n",
        "            logger.info(f\"Training Loss: {epoch_metrics['train_loss']:.4f}\")\n",
        "            logger.info(f\"Training FPS: {epoch_metrics['train_fps']:.2f}\")\n",
        "            logger.info(f\"Validation Loss: {epoch_metrics['val_loss']:.4f}\")\n",
        "            logger.info(f\"Validation FPS: {epoch_metrics['val_fps']:.2f}\")\n",
        "            logger.info(f\"Learning Rate: {epoch_metrics['learning_rate']:.6f}\")\n",
        "            logger.info(\"=\"*50 + \"\\n\")\n",
        "\n",
        "            if epoch_metrics['val_loss'] < best_map:\n",
        "                best_map = epoch_metrics['val_loss']\n",
        "                self.save_checkpoint(\n",
        "                    model, optimizer, scheduler,\n",
        "                    epoch_metrics, model_name, epoch,\n",
        "                    is_best=True\n",
        "                )\n",
        "\n",
        "            if (epoch + 1) % self.config.SAVE_FREQ == 0:\n",
        "                self.save_checkpoint(\n",
        "                    model, optimizer, scheduler,\n",
        "                    epoch_metrics, model_name, epoch\n",
        "                )\n",
        "\n",
        "            scheduler.step(epoch_metrics['val_loss'])\n",
        "\n",
        "        logger.info(\"\\nTraining Complete!\")\n",
        "        logger.info(f\"Best Validation Loss: {best_map:.4f}\")\n",
        "\n",
        "        avg_metrics = {\n",
        "            'train_loss': np.mean([m['train_loss'] for m in metrics_summary]),\n",
        "            'train_fps': np.mean([m['train_fps'] for m in metrics_summary]),\n",
        "            'val_loss': np.mean([m['val_loss'] for m in metrics_summary]),\n",
        "            'val_fps': np.mean([m['val_fps'] for m in metrics_summary])\n",
        "        }\n",
        "\n",
        "        logger.info(\"\\nAverage Metrics:\")\n",
        "        logger.info(f\"Avg Training Loss: {avg_metrics['train_loss']:.4f}\")\n",
        "        logger.info(f\"Avg Training FPS: {avg_metrics['train_fps']:.2f}\")\n",
        "        logger.info(f\"Avg Validation Loss: {avg_metrics['val_loss']:.4f}\")\n",
        "        logger.info(f\"Avg Validation FPS: {avg_metrics['val_fps']:.2f}\")\n",
        "\n",
        "        return metrics_summary"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:39:07.254205Z",
          "iopub.execute_input": "2024-11-18T15:39:07.254591Z",
          "iopub.status.idle": "2024-11-18T15:39:07.267490Z",
          "shell.execute_reply.started": "2024-11-18T15:39:07.254554Z",
          "shell.execute_reply": "2024-11-18T15:39:07.266506Z"
        },
        "id": "ptFzbhy_NJjx",
        "outputId": "c42bf674-05dd-44b2-b4bb-5c609de101b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Overwriting /kaggle/working/trainer.py\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/working/transforms.py\n",
        "\"\"\"\n",
        "Transforms for object detection\n",
        "\"\"\"\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class TransformFactory:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_train: bool = True):\n",
        "        \"\"\"Get transforms for training or validation\n",
        "\n",
        "        Args:\n",
        "            is_train: If True, return training transforms, else validation transforms\n",
        "\n",
        "        Returns:\n",
        "            torchvision.transforms.Compose object\n",
        "        \"\"\"\n",
        "        if is_train:\n",
        "            return T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.RandomHorizontalFlip(0.5),\n",
        "                T.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]\n",
        "                )\n",
        "            ])\n",
        "        else:\n",
        "            return T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225]\n",
        "                )\n",
        "            ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:19.063699Z",
          "iopub.execute_input": "2024-11-18T15:36:19.064063Z",
          "iopub.status.idle": "2024-11-18T15:36:19.076986Z",
          "shell.execute_reply.started": "2024-11-18T15:36:19.064009Z",
          "shell.execute_reply": "2024-11-18T15:36:19.076111Z"
        },
        "id": "G3BJ77xYNJjy",
        "outputId": "8bfe6238-3a95-40fa-c920-aa0c9903163c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Writing /kaggle/working/transforms.py\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /kaggle/working/config.py\n",
        "# config.py - Configuration settings\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    # Data paths\n",
        "    TRAIN_IMG_DIR = '/kaggle/working/HAD-v2-8/train'\n",
        "    TRAIN_ANNOTATIONS = '/kaggle/working/HAD-v2-8/train/_annotations.coco.json'\n",
        "    VAL_IMG_DIR = '/kaggle/working/HAD-v2-8/valid'\n",
        "    VAL_ANNOTATIONS = '/kaggle/working/HAD-v2-8/valid/_annotations.coco.json'\n",
        "\n",
        "    # Training parameters\n",
        "    NUM_CLASSES = 8  # 7 classes + background\n",
        "    BATCH_SIZE = 4\n",
        "    NUM_WORKERS = 2\n",
        "    DEVICE = 'cuda'\n",
        "    LOG_FILE = 'training.log'\n",
        "    SAVE_FREQ = 5      # Save checkpoint every N epochs\n",
        "    MODEL_DIR = 'models'\n",
        "\n",
        "    # Model configurations\n",
        "    BACKBONE = 'resnet50'\n",
        "    LEARNING_RATE = 0.0001\n",
        "    NUM_EPOCHS = 10\n",
        "    WEIGHT_DECAY = 0.0005\n",
        "\n",
        "# # dataset.py - Dataset handling\n",
        "# from dataset import COCODetectionDataset  # Using the code from your project files\n",
        "\n",
        "# # transforms.py - Data transformations\n",
        "# from transforms import TransformFactory  # Using the code from your project files\n",
        "\n",
        "# # trainer.py - Training implementation\n",
        "# from trainer import ObjectDetectionTrainer  # Using the code from your project files\n",
        "\n",
        "# # GPU_optimizer.py - GPU optimization\n",
        "# from GPU_optimizer import GPUOptimizer  # Using the code from your project files"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:19.078096Z",
          "iopub.execute_input": "2024-11-18T15:36:19.078385Z",
          "iopub.status.idle": "2024-11-18T15:36:19.090699Z",
          "shell.execute_reply.started": "2024-11-18T15:36:19.078355Z",
          "shell.execute_reply": "2024-11-18T15:36:19.089696Z"
        },
        "id": "j9Wdb1CnNJjz",
        "outputId": "cc322b5b-5267-46a3-a0d5-575103fa6eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Writing /kaggle/working/config.py\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:19.091764Z",
          "iopub.execute_input": "2024-11-18T15:36:19.092419Z",
          "iopub.status.idle": "2024-11-18T15:36:32.420616Z",
          "shell.execute_reply.started": "2024-11-18T15:36:19.092377Z",
          "shell.execute_reply": "2024-11-18T15:36:32.419546Z"
        },
        "id": "ON0Gl9jSNJjz",
        "outputId": "5cf1534c-09a8-4000-ca8b-2ee72614ac7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting pycocotools\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.8\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:32.421986Z",
          "iopub.execute_input": "2024-11-18T15:36:32.422341Z",
          "iopub.status.idle": "2024-11-18T15:36:44.605262Z",
          "shell.execute_reply.started": "2024-11-18T15:36:32.422295Z",
          "shell.execute_reply": "2024-11-18T15:36:44.604242Z"
        },
        "id": "1pcF6E-iNJj0",
        "outputId": "3d13b11c-fbfc-46cf-f419-edff9053ed8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting loguru\n  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\nDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: loguru\nSuccessfully installed loguru-0.7.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:36:44.606915Z",
          "iopub.execute_input": "2024-11-18T15:36:44.607767Z",
          "iopub.status.idle": "2024-11-18T15:36:58.018269Z",
          "shell.execute_reply.started": "2024-11-18T15:36:44.607719Z",
          "shell.execute_reply": "2024-11-18T15:36:58.017059Z"
        },
        "id": "OUjfOPRwNJj0",
        "outputId": "dbb6c7fc-607d-49f3-b664-a4e04e8a735c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting ultralytics\n  Downloading ultralytics-8.3.32-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.32-py3-none-any.whl (887 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.0/887.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.32 ultralytics-thop-2.0.11\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "from config import TrainingConfig\n",
        "from dataset import COCODetectionDataset\n",
        "from trainer import ObjectDetectionTrainer\n",
        "\n",
        "def main():\n",
        "    # Initialize config\n",
        "    config = TrainingConfig()\n",
        "\n",
        "    # Set up transforms\n",
        "    transform = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                   std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = COCODetectionDataset(\n",
        "        root=config.TRAIN_IMG_DIR,\n",
        "        annotation_file=config.TRAIN_ANNOTATIONS,\n",
        "        transforms=transform\n",
        "    )\n",
        "\n",
        "    val_dataset = COCODetectionDataset(\n",
        "        root=config.VAL_IMG_DIR,\n",
        "        annotation_file=config.VAL_ANNOTATIONS,\n",
        "        transforms=transform\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        collate_fn=ObjectDetectionTrainer.collate_fn\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        collate_fn=ObjectDetectionTrainer.collate_fn\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = ObjectDetectionTrainer(config)\n",
        "\n",
        "    # Train model\n",
        "    try:\n",
        "        metrics = trainer.train(\n",
        "            model_name='fasterrcnn',\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader\n",
        "        )\n",
        "        print(\"Training completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {str(e)}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:39:13.304245Z",
          "iopub.execute_input": "2024-11-18T15:39:13.304670Z",
          "iopub.status.idle": "2024-11-18T15:39:13.319442Z",
          "shell.execute_reply.started": "2024-11-18T15:39:13.304621Z",
          "shell.execute_reply": "2024-11-18T15:39:13.318531Z"
        },
        "id": "Frn6f5vxNJj3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-18T15:39:15.260890Z",
          "iopub.execute_input": "2024-11-18T15:39:15.261662Z"
        },
        "id": "DtQ1FzwWNJj3",
        "outputId": "6e75526b-ce4b-4291-ca07-772f31323c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "loading annotations into memory...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[32m2024-11-18 15:39:15.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mLoaded dataset with 8122 valid images and 7 classes\u001b[0m\n\u001b[32m2024-11-18 15:39:15.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mClasses: ['bus', 'car', 'crosswalk', 'person', 'stop sign', 'traffic light', 'truck']\u001b[0m\n\u001b[32m2024-11-18 15:39:15.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mLoaded dataset with 744 valid images and 7 classes\u001b[0m\n\u001b[32m2024-11-18 15:39:15.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mClasses: ['bus', 'car', 'crosswalk', 'person', 'stop sign', 'traffic light', 'truck']\u001b[0m\n`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n\u001b[32m2024-11-18 15:39:15.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36m_setup_logging\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mUsing device: cuda\u001b[0m\n\u001b[32m2024-11-18 15:39:15.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mStarting training for model: fasterrcnn\u001b[0m\n\u001b[32m2024-11-18 15:39:15.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36m_get_model\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mInitializing fasterrcnn model...\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Done (t=0.46s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.03s)\ncreating index...\nindex created!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 175MB/s] \n\u001b[32m2024-11-18 15:39:17.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36m_get_model\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mSuccessfully initialized fasterrcnn model\u001b[0m\n\u001b[32m2024-11-18 15:39:17.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mStarting epoch 0\u001b[0m\n\u001b[32m2024-11-18 15:39:20.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 0, Loss: 2.7994, LR: 0.000000, Memory: {'allocated': '699.1MB', 'cached': '5430.0MB', 'max_allocated': '4809.9MB'}\u001b[0m\n\u001b[32m2024-11-18 15:39:27.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 10, Loss: 2.6965, LR: 0.000001, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n\u001b[32m2024-11-18 15:39:33.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 20, Loss: 2.4622, LR: 0.000001, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n\u001b[32m2024-11-18 15:39:40.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 30, Loss: 2.1876, LR: 0.000002, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n\u001b[32m2024-11-18 15:39:47.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 40, Loss: 1.9420, LR: 0.000002, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n\u001b[32m2024-11-18 15:39:53.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 50, Loss: 1.7801, LR: 0.000003, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n\u001b[32m2024-11-18 15:40:00.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mtrain_one_epoch\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mEpoch 0, Iteration 60, Loss: 1.6348, LR: 0.000003, Memory: {'allocated': '699.2MB', 'cached': '5866.0MB', 'max_allocated': '5304.8MB'}\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "xbaqV1zRNJj3"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}